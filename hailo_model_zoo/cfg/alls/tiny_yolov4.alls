# normalization is folded onto the first convolution, see the .yaml configuration
# normalization1 = normalization([0.0, 0.0, 0.0], [255.0, 255.0, 255.0])
model_optimization_config(calibration, batch_size=8, calibset_size=64)
# pre_quantization_optimization commands
pre_quantization_optimization(equalization, policy=disabled)
pre_quantization_optimization(activation_clipping, layers=[conv19], mode=manual, clipping_values=[-20, 5])

# post_quantization_optimization commands
post_quantization_optimization(finetune, policy=enabled, learning_rate=0.0001, epochs=8, dataset_size=4000, loss_factors=[1.0, 2.0, 0.25, 0.125, 1.0, 2.0, 0.25, 0.125], loss_types=[l2, l2, l2, l2, l2, l2, l2, l2])

allocator_param(enable_partial_row_buffers=disabled)

