base:
- base/yolov5.yaml
inference:
  emulator_batch_size: 1
network:
  network_name: yolov7e6
preprocessing:
  input_shape:
  - 1280
  - 1280
  - 3
postprocessing:
  anchors:
    strides:
    - 8
    - 16
    - 32
    - 64
    sizes:
    - - 19
      - 27
      - 44
      - 40
      - 38
      - 94
    - - 96
      - 68
      - 86
      - 152
      - 180
      - 137
    - - 140
      - 301
      - 303
      - 264
      - 238
      - 542
    - - 436
      - 615
      - 739
      - 380
      - 925
      - 792
paths:
  alls_script: yolov7e6.alls
  network_path:
  - models_files/ObjectDetection/Detection-COCO/yolo/yolov7e6/pretrained/2022-10-19/yolov7-e6.onnx
  url: https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ObjectDetection/Detection-COCO/yolo/yolov7e6/pretrained/2022-10-19/yolov7-e6.zip
parser:
  nodes:
  - images
  - - Conv_516
    - Conv_513
    - Conv_510
    - Conv_507
info:
  input_shape: 1280x1280x3
  output_shape: 20x20x255, 40x40x255, 80x80x255, 160x160x255
  operations: 257.56G
  parameters: 97.20M
  framework: pytorch
  training_data: coco train2017
  validation_data: coco val2017
  eval_metric: mAP
  source: https://github.com/WongKinYiu/yolov7
  license_url: https://github.com/WongKinYiu/yolov7/blob/main/LICENSE.md
  full_precision_result: 55.367
