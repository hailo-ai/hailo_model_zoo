norm1 = normalization([127.5, 127.5, 127.5], [127.5, 127.5, 127.5])
model_optimization_flavor(optimization_level=0, compression_level=0)
pre_quantization_optimization(layer_norm_decomposition, equalization=disabled, bit_decomposition_mode=uniform_precision)
model_optimization_config(calibration, calibset_size=64)
quantization_param([norm1, conv1, conv1_s2d], precision_mode=a16_w16)
quantization_param([conv4, conv5, conv24, conv25], precision_mode=a16_w16)
quantization_param({ew_add*}, precision_mode=a16_w16)

resources_param(max_compute_utilization=1.0, max_control_utilization=0.95, max_memory_utilization=0.75)