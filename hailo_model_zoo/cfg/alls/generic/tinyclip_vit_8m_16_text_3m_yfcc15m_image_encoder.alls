norm1 = normalization([122.7709383, 116.7460125, 104.09373615000001], [68.5005327, 66.6321579, 70.32316304999999])
model_optimization_flavor(optimization_level=0, compression_level=0)
quantization_param({conv42}, precision_mode=a16_w16)
quantization_param({ew_add*}, precision_mode=a16_w16)
quantization_param({norm*}, precision_mode=a16_w16)
quantization_param([conv1_s2d, conv1], precision_mode=a16_w16)
quantization_param({conv_feature*}, precision_mode=a8_w8) 
pre_quantization_optimization(layer_norm_decomposition, equalization=disabled, bit_decomposition_mode=uniform_precision)
model_optimization_config(calibration, calibset_size=64)
pre_quantization_optimization(decompose_conv_factor, policy=enabled)

performance_param(compiler_optimization_level=max)