normalization1 = normalization([0.0, 0.0, 0.0], [255.0, 255.0, 255.0])
change_output_activation(sigmoid)
resize_input1 = resize(input_layer1, resize_shapes=[1080, 1920])
model_optimization_config(calibration, batch_size=4, calibset_size=64)
post_quantization_optimization(bias_correction, policy=disabled)
post_quantization_optimization(finetune, policy=enabled, meta_arch=yolo, dataset_size=4096, batch_size=4, epochs=5, learning_rate=0.0002, loss_layer_names=[conv92, conv93, conv82, conv84, conv72, conv74], loss_types=[l2rel, l2rel, l2rel, l2rel, l2rel, l2rel])
quantization_param(conv28, precision_mode=a8_w4)
quantization_param(conv32, precision_mode=a8_w4)
quantization_param(conv34, precision_mode=a8_w4)
quantization_param(conv36, precision_mode=a8_w4)
quantization_param(conv38, precision_mode=a8_w4)
quantization_param(conv40, precision_mode=a8_w4)
quantization_param(conv42, precision_mode=a8_w4)
quantization_param(conv45, precision_mode=a8_w4)
quantization_param(conv46, precision_mode=a8_w4)
quantization_param(conv50, precision_mode=a8_w4)
quantization_param(conv52, precision_mode=a8_w4)
quantization_param(conv54, precision_mode=a8_w4)
quantization_param(conv55, precision_mode=a8_w4)
quantization_param(conv59, precision_mode=a8_w4)
quantization_param(conv61, precision_mode=a8_w4)
quantization_param(conv73, precision_mode=a8_w4)
quantization_param(conv78, precision_mode=a8_w4)
quantization_param(conv80, precision_mode=a8_w4)
quantization_param(conv83, precision_mode=a8_w4)
quantization_param(conv85, precision_mode=a8_w4)
quantization_param(conv86, precision_mode=a8_w4)
quantization_param(conv88, precision_mode=a8_w4)
quantization_param(conv90, precision_mode=a8_w4)
quantization_param(conv92, precision_mode=a8_w4)
quantization_param(output_layer1, precision_mode=a8_w8)
quantization_param(output_layer2, precision_mode=a8_w8)
quantization_param(output_layer3, precision_mode=a8_w8)
reshape, yuv_to_rgb1 = input_conversion(input_layer1, nv12_to_rgb, emulator_support=True)
