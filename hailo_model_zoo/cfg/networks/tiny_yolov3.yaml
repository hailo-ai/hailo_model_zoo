base:
- base/yolo.yaml
preprocessing:
  input_shape: null
  meta_arch: mobilenet_ssd_ar
postprocessing:
  nms_iou_thresh: 0.3
  score_threshold: 0.1
  meta_arch: yolo_v3
  anchors:
    strides:
    - 16
    - 32
    sizes:
    - - 23
      - 27
      - 37
      - 58
      - 81
      - 82
    - - 81
      - 82
      - 135
      - 169
      - 344
      - 319
network:
  network_name: tiny_yolov3
paths:
  alls_script: tiny_yolov3.alls
  network_path:
  - models_files/ObjectDetection/Detection-COCO/yolo/tiny_yolov3/pretrained/2021-07-11/frozen_tiny_yolo_v3.pb
  url: https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ObjectDetection/Detection-COCO/yolo/tiny_yolov3/pretrained/2021-07-11/tiny_yolov3.zip
parser:
  nodes:
  - import/detector/yolo-v3-tiny/Conv/Conv2D
  - - import/detector/yolo-v3-tiny/Conv_9/BiasAdd
    - import/detector/yolo-v3-tiny/Conv_12/BiasAdd
info:
  task: object detection
  input_shape: 416x416x3
  output_shape: 13x13x6, 13x13x6, 13x13x3, 13x13x240, 26x26x6, 26x26x6, 26x26x3, 26x26x240
  operations: 2.79G
  parameters: 8.85M
  framework: pytorch
  training_data: coco train2017
  validation_data: coco val2017
  eval_metric: mAP
  full_precision_result: 14.36
  source: https://github.com/Tianxiaomo/pytorch-YOLOv4
  license_url: https://www.apache.org/licenses/LICENSE-2.0
