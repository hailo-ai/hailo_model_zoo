norm1 = normalization([122.7709383, 116.7460125, 104.09373615000001], [68.5005327, 66.6321579, 70.32316304999999])
model_optimization_flavor(optimization_level=0, compression_level=0)
quantization_param({ew_add*}, precision_mode=a16_w16)
quantization_param({norm*}, precision_mode=a16_w16)
quantization_param([conv1, slice1, conv98, format_conversion1], precision_mode=a16_w16)
pre_quantization_optimization(layer_norm_decomposition, equalization=disabled, bit_decomposition_mode=uniform_precision)
model_optimization_config(calibration, calibset_size=64)

allocator_param(disable_row_per_cut=True, enable_auto_spatial_reshapes=False, enable_fixer=max_adjcents)
performance_param(compiler_optimization_level=2, optimize_for_batch=8)
context_switch_param(auto_partition_to_buckets=True, berkitizer_bucket_size=80, berkitizer_min_size=300, mode=enabled, share_buckets_partition=False, slotter_chances=200, toposort_mode=pushdown)

clip_vit_l_14_laion2B_image_encoder/placeholder = format_conversion(clip_vit_l_14_laion2B_image_encoder/const_input2, clip_vit_l_14_laion2B_image_encoder/ew_add1, spatial_reshape, 33, 8, collapse=True)
remove_node(clip_vit_l_14_laion2B_image_encoder/format_conversion1)
clip_vit_l_14_laion2B_image_encoder/transpose_width_features_from_conv1 = format_conversion(clip_vit_l_14_laion2B_image_encoder/conv1, clip_vit_l_14_laion2B_image_encoder/concat1, transpose_width_features)
clip_vit_l_14_laion2B_image_encoder/reshape_height_features_from_transpose_width_features_from_conv1 = format_conversion(clip_vit_l_14_laion2B_image_encoder/transpose_width_features_from_conv1, clip_vit_l_14_laion2B_image_encoder/concat1, reshape_height_features, 256, 1, collapse=False)
clip_vit_l_14_laion2B_image_encoder/transpose_width_features_from_const_input1 = format_conversion(clip_vit_l_14_laion2B_image_encoder/const_input1, clip_vit_l_14_laion2B_image_encoder/concat1, transpose_width_features)
clip_vit_l_14_laion2B_image_encoder/placeholder = format_conversion(clip_vit_l_14_laion2B_image_encoder/concat1, clip_vit_l_14_laion2B_image_encoder/ew_add1, spatial_reshape, 257, 1024, collapse=True)
clip_vit_l_14_laion2B_image_encoder/reshape_height_features_from_concat1 = format_conversion(clip_vit_l_14_laion2B_image_encoder/concat1, clip_vit_l_14_laion2B_image_encoder/ew_add1, reshape_height_features, 33, 8, collapse=False)
clip_vit_l_14_laion2B_image_encoder/transpose_width_features_from_concat1 = format_conversion(clip_vit_l_14_laion2B_image_encoder/reshape_height_features_from_concat1, clip_vit_l_14_laion2B_image_encoder/ew_add1, transpose_width_features)
pre = bucket([clip_vit_l_14_laion2B_image_encoder/input_layer1, clip_vit_l_14_laion2B_image_encoder/const_input1, clip_vit_l_14_laion2B_image_encoder/const_input2, clip_vit_l_14_laion2B_image_encoder/normalization1])
b0 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization2, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization2, clip_vit_l_14_laion2B_image_encoder/ew_add2, clip_vit_l_14_laion2B_image_encoder/ew_add3, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization4, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization4, clip_vit_l_14_laion2B_image_encoder/ew_add4, clip_vit_l_14_laion2B_image_encoder/ew_add5, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization6, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization6, clip_vit_l_14_laion2B_image_encoder/ew_add6, clip_vit_l_14_laion2B_image_encoder/ew_add7])
b3 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization8, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization8, clip_vit_l_14_laion2B_image_encoder/ew_add8, clip_vit_l_14_laion2B_image_encoder/ew_add9, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization10, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization10, clip_vit_l_14_laion2B_image_encoder/ew_add10, clip_vit_l_14_laion2B_image_encoder/ew_add11, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization12, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization12, clip_vit_l_14_laion2B_image_encoder/ew_add12, clip_vit_l_14_laion2B_image_encoder/ew_add13])
b6 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization14, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization14, clip_vit_l_14_laion2B_image_encoder/ew_add14, clip_vit_l_14_laion2B_image_encoder/ew_add15, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization16, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization16, clip_vit_l_14_laion2B_image_encoder/ew_add16, clip_vit_l_14_laion2B_image_encoder/ew_add17, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization18, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization18, clip_vit_l_14_laion2B_image_encoder/ew_add18, clip_vit_l_14_laion2B_image_encoder/ew_add19])
b9 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization20, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization20, clip_vit_l_14_laion2B_image_encoder/ew_add20, clip_vit_l_14_laion2B_image_encoder/ew_add21, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization22, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization22, clip_vit_l_14_laion2B_image_encoder/ew_add22, clip_vit_l_14_laion2B_image_encoder/ew_add23, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization24, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization24, clip_vit_l_14_laion2B_image_encoder/ew_add24, clip_vit_l_14_laion2B_image_encoder/ew_add25])
b12 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization26, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization26, clip_vit_l_14_laion2B_image_encoder/ew_add26, clip_vit_l_14_laion2B_image_encoder/conv53, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization28, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization28, clip_vit_l_14_laion2B_image_encoder/ew_add28, clip_vit_l_14_laion2B_image_encoder/ew_add29, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization30, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization30, clip_vit_l_14_laion2B_image_encoder/ew_add30, clip_vit_l_14_laion2B_image_encoder/ew_add31])
b15 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization32, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization32, clip_vit_l_14_laion2B_image_encoder/ew_add32, clip_vit_l_14_laion2B_image_encoder/ew_add33, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization34, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization34, clip_vit_l_14_laion2B_image_encoder/ew_add34, clip_vit_l_14_laion2B_image_encoder/ew_add35, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization36, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization36, clip_vit_l_14_laion2B_image_encoder/ew_add36, clip_vit_l_14_laion2B_image_encoder/ew_add37])
b18 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization38, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization38, clip_vit_l_14_laion2B_image_encoder/ew_add38, clip_vit_l_14_laion2B_image_encoder/ew_add39, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization40, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization40, clip_vit_l_14_laion2B_image_encoder/ew_add40, clip_vit_l_14_laion2B_image_encoder/ew_add41, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization42, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization42, clip_vit_l_14_laion2B_image_encoder/ew_add42, clip_vit_l_14_laion2B_image_encoder/ew_add43])
b21 = bucket([clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization44, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization44, clip_vit_l_14_laion2B_image_encoder/ew_add44, clip_vit_l_14_laion2B_image_encoder/ew_add45, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization46, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization46, clip_vit_l_14_laion2B_image_encoder/ew_add46, clip_vit_l_14_laion2B_image_encoder/ew_add47, clip_vit_l_14_laion2B_image_encoder/reduce_mean1_layer_normalization48, clip_vit_l_14_laion2B_image_encoder/ew_sub1_layer_normalization48, clip_vit_l_14_laion2B_image_encoder/ew_add48, clip_vit_l_14_laion2B_image_encoder/ew_add49])
post = bucket([clip_vit_l_14_laion2B_image_encoder/slice1, clip_vit_l_14_laion2B_image_encoder/output_layer1])