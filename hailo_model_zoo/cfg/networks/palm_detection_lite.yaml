base:
- base/base.yaml
evaluation:
  dataset_name: hand_detection
  network_type: landmark_detection
  classes: 0
  data_set: null
  validation_data_set: null
postprocessing:
  meta_arch: ssd
  nms_iou_thresh: 0.6
  score_threshold: 0.5
  anchors:
    interpolated_scale_aspect_ratio: 1.0
    aspect_ratios:
    - 1.0
    max_scale: 0.75
    min_scale: 0.1484375
    scales: []
    num_layers: 4
    scale_factors:
    - 192.0
    - 192.0
    - 192.0
    - 192.0
    type: palm
preprocessing:
  network_type: detection
  meta_arch: face_landmark_cnn
parser:
  nodes:
  - input
  - - const_fold_opt__667/BiasAdd
    - const_fold_opt__554/BiasAdd
    - const_fold_opt__655/BiasAdd
    - const_fold_opt__626/BiasAdd
  normalization_params:
    normalize_in_net: true
    mean_list:
    - 0.0
    - 0.0
    - 0.0
    std_list:
    - 255.0
    - 255.0
    - 255.0
quantization:
  calib_set: null
paths:
  alls_script: palm_detection_lite.alls
  network_path:
  - models_files/ObjectDetection/Detection-Palm/2022-02-07/palm_detection_lite.ckpt.meta
  - models_files/ObjectDetection/Detection-Palm/2022-02-07/palm_detection_lite.ckpt.index
  - models_files/ObjectDetection/Detection-Palm/2022-02-07/palm_detection_lite.ckpt.data-00000-of-00001
  url: https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ObjectDetection/Detection-Palm/palm_detection_lite/pretrained/palm_detection_lite.zip
allocation:
  required_fps: 25
network:
  network_name: palm_detection_lite
info:
  task: palm detection
  input_shape: 192x192x3
  output_shape: 24x24x2, 24x24x36, 12x12x6, 12x12x108
  operations: 0.31G
  parameters: 1.01M
  framework: tflite
  training_data: internal
  validation_data: internal
  validation_data_set: N/A
  eval_metric: MNAE
  full_precision_result: 12.02
  source: https://github.com/google/mediapipe
  license_url: https://www.apache.org/licenses/LICENSE-2.0
